# -*- coding: utf-8 -*-
"""
Google's Speech Commands Dataset
================================
The Speech Commands Dataset has 65,000 one-second long utterances of 30 short 
words, by thousands of different people, contributed by members of the public
through the AIY website. Itâ€™s released under a Creative Commons BY 4.0 license.

More info about the dataset can be found at the link below:

https://research.googleblog.com/2017/08/launching-speech-commands-dataset.html

AIY website for contributing recordings:

https://aiyprojects.withgoogle.com/open_speech_recording

Tutorial on creating a word classifier:

https://www.tensorflow.org/versions/master/tutorials/audio_recognition
"""

import os, glob
import numpy as np
from scipy.io import wavfile

try:
    import sounddevice as sd

    have_sounddevice = True
except:
    have_sounddevice = False

from .utils import download_uncompress
from .base import Meta, AudioSample, Dataset

url = "http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz"


class GoogleSpeechCommands(Dataset):
    """
    This class will load the Google Speech Commands Dataset in a
    structure that is convenient to be processed.

    Attributes
    ----------
    basedir: str
        The directory where the Speech Commands Dataset is located/downloaded.
    size_by_samples: dict
        A dictionary whose keys are the words in the dataset. The values are the number of occurances for that particular word.
    subdirs: list
        The list of subdirectories in ``basedir``, where each sound type is the name of a subdirectory.
    classes: list
        The list of all sounds, same as the keys of ``size_by_samples``.

    Parameters
    ----------
    basedir: str, optional
        The directory where the Google Speech Commands dataset is located/downloaded. By default, this is the current directory.
    download: bool, optional
        If the corpus does not exist, download it.
    build: bool, optional
        Whether or not to build the dataset. By default, it is.
    subset: int, optional
        Build a dataset that contains all noise samples and `subset` samples per word. By default, the dataset will be built with all samples.
    seed: int, optional
        Which seed to use for the random generator when selecting a subset of samples. By default, ``seed=0``.
    """

    def __init__(
        self, basedir=None, download=False, build=True, subset=None, seed=0, **kwargs
    ):

        # initialize
        Dataset.__init__(self)
        self.size_by_samples = {}

        # default base directory is the current one
        self.basedir = basedir
        if basedir is None:
            self.basedir = "./google_speech_commands"

        # check the directory exists and download otherwise
        if not os.path.exists(self.basedir):
            if download:
                print("Downloading", url, "into", self.basedir, "...")
                download_uncompress(url=url, path=self.basedir)
            else:
                raise ValueError(
                    "Dataset directory does not exist. Create or set download option."
                )
        else:
            print("Dataset exists! Using %s" % self.basedir)

        # set seed of random number generator
        self.seed = seed
        self.rng = np.random.RandomState(seed)

        if build:
            self.build_corpus(subset, **kwargs)

    def build_corpus(self, subset=None, **kwargs):
        """
        Build the corpus with some filters (speech or not speech, sound type).
        """

        self.subdirs = glob.glob(os.path.join(self.basedir, "*", "."))
        self.classes = [s.split(os.sep)[-2] for s in self.subdirs]

        # go through all subdirectories / soundtypes
        for idx, word in enumerate(self.classes):

            if word == "_background_noise_":
                speech = False
            else:
                speech = True

            # get all list of all files in the subdirectory
            word_path = self.subdirs[idx]
            files = glob.glob(os.path.join(word_path, "*.wav"))

            # for speech files, select desired subset
            if subset and speech:
                rand_idx = np.arange(len(files))
                n_files = min(subset, len(files))
                self.rng.shuffle(rand_idx)
                files = [files[i] for i in rand_idx[:n_files]]

            self.size_by_samples[word] = len(files)

            # add each file to the corpus
            for filename in files:

                file_loc = os.path.join(self.basedir, word, os.path.basename(filename))

                # could also add score of original model for each word?
                if speech:
                    meta = Meta(word=word, speech=speech, file_loc=file_loc)
                else:
                    noise_type = os.path.basename(filename).split(".")[0]
                    meta = Meta(
                        word="NA",
                        noise_type=noise_type,
                        speech=speech,
                        file_loc=file_loc,
                    )

                if meta.match(**kwargs):
                    self.add_sample(GoogleSample(filename, **meta.as_dict()))

    def filter(self, **kwargs):
        """
        Filter the dataset and select samples that match the criterias provided
        The arguments to the keyword can be 1) a string, 2) a list of strings, 3)
        a function. There is a match if one of the following is True.

        1. ``value == attribute``
        2. ``value`` is a list and ``attribute in value == True``
        3. ``value`` is a callable (a function) and ``value(attribute) == True``
        """

        # first, create the new empty corpus
        new_corpus = GoogleSpeechCommands(
            basedir=self.basedir, build=False, seed=self.seed
        )

        # finally, add all the sentences
        for s in self.samples:
            new_corpus.add_sample_matching(s, **kwargs)

        return new_corpus


class GoogleSample(AudioSample):
    """
    Create the sound object.

    Parameters
    ----------
    path: str
      the path to the audio file
    **kwargs:
      metadata as a list of keyword arguments

    Attributes
    ----------
    data: array_like
      the actual audio signal
    fs: int
      sampling frequency
    """

    def __init__(self, path, **kwargs):
        """
        Create the the sound object
        path: string
          the path to a particular sample
        """

        fs, data = wavfile.read(path)
        AudioSample.__init__(self, data, fs, **kwargs)

    def __str__(self):
        """string representation"""

        if self.meta.speech:
            template = (
                "speech: " "{speech}" "; word: " "{word}" "; file_loc: " "{file_loc}" ""
            )
        else:
            template = (
                "speech: "
                "{speech}"
                "; noise type: "
                "{noise_type}"
                "; file_loc: "
                "{file_loc}"
                ""
            )
        s = template.format(**self.meta.as_dict())
        return s

    def plot(self, **kwargs):
        """Plot the spectogram"""
        try:
            import matplotlib.pyplot as plt
        except ImportError:
            print("Warning: matplotlib is required for plotting")
            return
        AudioSample.plot(self, **kwargs)
        if self.meta.speech:
            plt.title(self.meta.file_loc)
        else:
            plt.title(self.meta.file_loc)
